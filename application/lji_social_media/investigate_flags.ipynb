{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tiktoken\n",
    "import concurrent.futures\n",
    "import asyncio\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from typing import Any, List, Dict, Optional\n",
    "from openai import RateLimitError\n",
    "\n",
    "# from openai.error import RateLimitError\n",
    "import backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/libraries/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import libraries.llm_functions as lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules from libraries\n",
    "try:\n",
    "    from libraries import llm_functions as lf\n",
    "    from libraries import neo4j_lib as nl\n",
    "    from libraries import claude_prompts as cp\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core import VectorStoreIndex, Document\n",
    "\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up logging\n",
    "\n",
    "# Model and memory configurations\n",
    "llm = Ollama(\n",
    "    model=\"llama3.1:latest\", temperature=0, max_tokens=64768, request_timeout=120.0\n",
    ")\n",
    "llm = OpenAI(temperature=0, model=\"gpt-4o-mini\", request_timeout=120.0)\n",
    "MEMORY = ChatMemoryBuffer.from_defaults(token_limit=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat_engine(advert: str) -> Optional[Any]:\n",
    "    documents = [Document(text=advert)]\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    return index.as_chat_engine(\n",
    "        chat_mode=\"context\",\n",
    "        llm=llm,\n",
    "        memory=MEMORY,\n",
    "        system_prompt=(\n",
    "            \"As a career forensic analyst, you have deep insight into crime \"\n",
    "            \"and criminal activity, especially human trafficking. Investigate \"\n",
    "            \"the online recruitment advert and extract pertinent details.\"\n",
    "        ),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDn = 573388\n",
    "advert = nl.get_neo4j_advert(IDn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_name='assure_prompt'\n",
    "chat_engine = create_chat_engine(advert)\n",
    "analysis = lf.analyse_advert(chat_engine, prompt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
