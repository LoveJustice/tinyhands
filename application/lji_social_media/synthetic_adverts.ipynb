{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries.claude_prompts import CLAUDE_PROMPTS\n",
    "import os\n",
    "import sys\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "def count_tokens(text, model_name):\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "# Import modules from libraries\n",
    "try:\n",
    "    from libraries import llm_functions as lf\n",
    "    from libraries import neo4j_lib as nl\n",
    "    from libraries import claude_prompts as cp\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "import streamlit as st\n",
    "\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core import VectorStoreIndex, Document\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import Optional, Dict, Any\n",
    "import re\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from typing import Any, List, Optional\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"o1-mini\", request_timeout=120.0)\n",
    "# llm = Ollama(model=\"llama3.1\", temperature=0, max_tokens=4096)\n",
    "# llm = Anthropic(temperature=0, model=\"claude-3-opus-20240229\")\n",
    "# llm = Anthropic()\n",
    "# MEMORY = ChatMemoryBuffer.from_defaults(token_limit=32768, memory_limit=1)\n",
    "MEMORY = ChatMemoryBuffer.from_defaults(token_limit=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAUDE_PROMPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assure_prompt                         124\n",
    "bypass_prompt                         126\n",
    "callback_request_prompt                61\n",
    "drop_off_at_secure_location_prompt     25\n",
    "false_organization_prompt              35\n",
    "gender_specific_prompt                  2\n",
    "illegal_activities_prompt               3\n",
    "immediate_hiring_prompt                64\n",
    "language_switch_prompt                 32\n",
    "multiple_provinces_prompt              53\n",
    "no_education_skilled_prompt             6\n",
    "no_location_prompt                    199\n",
    "overseas_prompt                         7\n",
    "quick_money_prompt                     34\n",
    "recruit_students_prompt                 3\n",
    "requires_references                     1\n",
    "suspicious_email_prompt                12\n",
    "target_specific_group_prompt           42\n",
    "unprofessional_writing_prompt          25\n",
    "unrealistic_hiring_number_prompt       30\n",
    "unusual_hours_prompt                   34\n",
    "vague_description_prompt              227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_flags = ['gender_specific_prompt','illegal_activities_prompt','no_education_skilled_prompt','overseas_prompt','recruit_students_prompt','requires_references']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "\n",
    "gender_specific_prompt                  2\n",
    "illegal_activities_prompt               3\n",
    "no_education_skilled_prompt             6\n",
    "overseas_prompt                         7\n",
    "recruit_students_prompt                 3\n",
    "requires_references                     1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_name = 'gender_specific_prompt'\n",
    "query = \"\"\"\n",
    "MATCH (g:Group)-[:HAS_POSTING]-(n:Posting)-[:HAS_ANALYSIS {type: $prompt_name}]-(analysis:Analysis)\n",
    "WHERE g.country_id = 1\n",
    "  AND n.text IS NOT NULL\n",
    "  AND n.text <> \"\"\n",
    "RETURN ID(n) AS IDn, n.post_id AS post_id, n.text AS advert, analysis.result as result\n",
    "\"\"\"\n",
    "parameters = {\"prompt_name\": prompt_name}\n",
    "adverts = pd.DataFrame(nl.execute_neo4j_query(query, parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"Assistant, consider the following recruitment advert.  Notice the requirement to provide references.  I want you to change the following advert so that it als requires references.  Be original and creative.  Do not change ANY of the other factual detail.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adverts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_results = adverts.loc[adverts.result=='yes',]\n",
    "# documents = [Document(text=advert)]\n",
    "docs=[]\n",
    "for idx,row in yes_results.iterrows():\n",
    "    advert = row['advert']\n",
    "    docs.append(advert)\n",
    "    # print(advert)\n",
    "    # Document(advert)\n",
    "documents = [Document(text=advert) for advert in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_results = adverts.loc[adverts.result=='no',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(advert.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)\n",
    "Document(advert.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat_engine(documents):\n",
    "    if advert:\n",
    "        index = VectorStoreIndex.from_documents(documents)\n",
    "        return index.as_chat_engine(\n",
    "            chat_mode=\"context\",\n",
    "            llm=llm,\n",
    "            memory=MEMORY,\n",
    "            system_prompt=(\n",
    "                \"A a career forensic analyst you have deep insight into crime and criminal activity especially human trafficking.  \"\n",
    "                \"Your express goal is to investigate online recruitment advert and extract pertinent factual detail.\"\n",
    "            ),\n",
    "        )\n",
    "    else:\n",
    "        st.error(f\"Failed to extract text from URL: {advert}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Assistant, consider the following recruitment advert:{advert}.  I want you to add to it so that the following prompt will be TRUE: \n",
    "'{CLAUDE_PROMPTS[prompt_name]}'.  \n",
    " Be original and creative but do not change ANY of the other factual detail. Try to mimic the style and tone of the provided adverts.  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYSIS_STR = \"\"\"' Return your analysis STRICTLY and exclusively in the following JSON format:  {\"new_advert\": \"advert\", \"changes\": [\"change 1\", \"change 2\", ...] or [].'\n",
    " Please do not use ANY other embedded explanation and please do not use backticks.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine = create_chat_engine(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = response.response\n",
    "new_advert = json.loads(answer)['new_advert']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat_engine(documents):\n",
    "    if advert:\n",
    "        index = VectorStoreIndex.from_documents(documents)\n",
    "        return index.as_chat_engine(\n",
    "            chat_mode=\"context\",\n",
    "            llm=llm,\n",
    "            memory=MEMORY,\n",
    "            system_prompt=(\n",
    "                \"A a career forensic analyst you have deep insight into crime and criminal activity especially human trafficking.  \"\n",
    "                \"Your express goal is to investigate online recruitment advert and extract pertinent factual detail.\"\n",
    "            ),\n",
    "        )\n",
    "    else:\n",
    "        st.error(f\"Failed to extract text from URL: {advert}\")\n",
    "        return None\n",
    "\n",
    "sparse_flags = ['gender_specific_prompt','illegal_activities_prompt','no_education_skilled_prompt','overseas_prompt','recruit_students_prompt','requires_references']\n",
    "\n",
    "all_sparse_results = []\n",
    "for prompt_name in sparse_flags:\n",
    "    query = \"\"\"\n",
    "    MATCH (g:Group)-[:HAS_POSTING]-(n:Posting)-[:HAS_ANALYSIS {type: $prompt_name}]-(:Analysis {result:'no'})\n",
    "    WHERE g.country_id = 1\n",
    "      AND n.text IS NOT NULL\n",
    "      AND n.text <> \"\"\n",
    "    RETURN ID(n) AS IDn, n.post_id AS post_id, n.text AS advert\n",
    "    \"\"\"\n",
    "    parameters = {\"prompt_name\": prompt_name}\n",
    "    advert_sample = pd.DataFrame(nl.execute_neo4j_query(query, parameters)).sample(5)\n",
    "    docs=[]\n",
    "    for idx,row in advert_sample.iterrows():\n",
    "        advert = row['advert']\n",
    "        docs.append(advert)\n",
    "        # print(advert)\n",
    "        # Document(advert)\n",
    "    documents = [Document(text=advert) for advert in docs]\n",
    "    chat_engine = create_chat_engine(documents)\n",
    "    advert_responses = []\n",
    "    for idx,row in advert_sample.iterrows():\n",
    "        result={}\n",
    "        advert = row['advert']\n",
    "        prompt = f\"\"\"Assistant, consider the following recruitment advert:{advert}.  I want you to add to it so that the following prompt will be TRUE: \n",
    "        '{CLAUDE_PROMPTS[prompt_name]}'.  \n",
    "         Be subtle, be original and be creative, but do not change ANY of the other factual detail. Please mimic the grammar, style and tone of the provided adverts.  \"\"\"\n",
    "        response = chat_engine.chat(prompt+ANALYSIS_STR)\n",
    "        new_advert = json.loads(answer)['new_advert']\n",
    "        result['new_advert'] = new_advert\n",
    "        result['advert'] = advert\n",
    "        result['IDn'] = row['IDn']\n",
    "        advert_responses.append(result)\n",
    "    all_sparse_results.append(advert_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
